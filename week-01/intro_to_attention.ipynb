{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YashRavv/ai-mastery-journey/blob/main/week-01/intro_to_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkURO_VWilPO"
      },
      "source": [
        "# üß† Intro to Attention Mechanism\n",
        "\n",
        "Welcome to your first AI Mastery notebook! In this notebook, you'll:\n",
        "- Understand the **intuition behind attention**\n",
        "- Visualize **dot products** as similarity scores\n",
        "- Simulate a basic **Query-Key-Value (QKV)** attention mechanism\n",
        "\n",
        "> Let‚Äôs explore what makes transformers so powerful ‚Äì the ability to *focus attention* where it matters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3TmRN-UilPR"
      },
      "source": [
        "## üìò What is Attention, Really?\n",
        "\n",
        "**Analogy:** Imagine reading a sentence:\n",
        "> \"The lion saw the zebra near the river.\"\n",
        "\n",
        "If you're trying to predict the word *river*, the model should focus more on *zebra* and *near*.\n",
        "\n",
        "**Attention** helps the model assign **weights** to other words based on how relevant they are.\n",
        "\n",
        "We'll simulate this with simple vectors next!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grZ4dUzRilPS",
        "outputId": "a160c387-6baf-497c-8894-7e142bbfae5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity with key1: 1\n",
            "Similarity with key2: 0\n"
          ]
        }
      ],
      "source": [
        "# üßÆ Dot Product as Similarity\n",
        "import numpy as np\n",
        "\n",
        "def dot_product_similarity(vec1, vec2):\n",
        "    return np.dot(vec1, vec2)\n",
        "\n",
        "# Define a Query and two Keys\n",
        "query = np.array([1, 0])\n",
        "key1 = np.array([1, 1])   # Related word\n",
        "key2 = np.array([0, 1])   # Less related\n",
        "\n",
        "print(\"Similarity with key1:\", dot_product_similarity(query, key1))\n",
        "print(\"Similarity with key2:\", dot_product_similarity(query, key2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TP987VQilPT"
      },
      "source": [
        "## üéØ What You Just Did\n",
        "- Query is trying to match \"relevant\" keys.\n",
        "- Dot product gives a *similarity score* (higher = more relevant)\n",
        "- This is the heart of attention!\n",
        "\n",
        "Next, we'll simulate **scaled dot-product attention** with softmax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozAIDWo-ilPT",
        "outputId": "f23b5a36-45f3-49b1-93f8-a3c1022ac2f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention scores: [1 0 1]\n",
            "Attention weights: [0.4223188 0.1553624 0.4223188]\n"
          ]
        }
      ],
      "source": [
        "# üîÅ Attention Mechanism with Softmax\n",
        "from scipy.special import softmax\n",
        "\n",
        "# Define a query and 3 keys\n",
        "query = np.array([1, 0])\n",
        "keys = np.array([\n",
        "    [1, 1],   # More relevant\n",
        "    [0, 1],   # Less relevant\n",
        "    [1, 0]    # Highly aligned\n",
        "])\n",
        "\n",
        "# Compute dot products\n",
        "scores = np.dot(keys, query)\n",
        "weights = softmax(scores)\n",
        "\n",
        "print(\"Attention scores:\", scores)\n",
        "print(\"Attention weights:\", weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_YZ0hjWilPU"
      },
      "source": [
        "## üìù Reflect:\n",
        "- What does attention *focus on* in this case?\n",
        "- Try changing the query or keys ‚Äî what happens?\n",
        "\n",
        "Feel free to edit below and jot down your thoughts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_GUx3pbZilPU"
      },
      "outputs": [],
      "source": [
        "# ‚úçÔ∏è Your reflections here:\n",
        "# 1. What surprised you?\n",
        "# 2. What confused you?\n",
        "# 3. How does this relate to LLMs?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}